{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ripRish/SENTIMENT-ANALYSIS-ON-DEPRESSION/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU-LEknwq2ls",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rccRwrveYuzm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "7Jv8DWnWaFiA",
    "outputId": "6f93a43e-6a2c-4b7d-99d6-7b727cf69790",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rk\\pycharmprojects\\pythonproject\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#lokavah728@veb65.com\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#NOPASSWORD\u001B[39;00m\n\u001B[0;32m      3\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m pip install -q kaggle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m files\n\u001B[0;32m      5\u001B[0m files\u001B[38;5;241m.\u001B[39mupload()\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#lokavah728@veb65.com\n",
    "#NOPASSWORD\n",
    "! pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WddVYnyPawEu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muOfx_vmWgpa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Set Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV5uZMGjbdEI",
    "outputId": "1e28707f-1ac0-4634-a3d7-386e920c1d00",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download -d ywang311/twitter-sentiment -p /content/sample_data/ --unzip\n",
    "! kaggle datasets download -d kazanova/sentiment140 -p /content/sample_data/ --unzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amxs7B5IWo1B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data set Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITQEMMgPehJM",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "edc943c1-77da-4590-c185-04ff90c6694f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "dataset_1=pd.read_csv('/content/sample_data/training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1',usecols=[0,5])\n",
    "dataset_1.columns = ['Sentiment','SentimentText']\n",
    "dataset_2 = pd.read_csv('/content/sample_data/Sentiment Analysis Dataset 2.csv',encoding='ISO-8859-1',skiprows=[8835,535881],usecols=[1,3])\n",
    "dataset = pd.concat([dataset_1,dataset_2], axis=0,ignore_index=True)\n",
    "dataset\n",
    "data=dataset.values.tolist()\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Data** **Cleaning**: \n",
    "textStemming :- removing URLS , Emojis, numbers \n",
    "Lemmatization :- Grammatically simple sentence "
   ],
   "metadata": {
    "id": "4a2UNy_6UJNB",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABB8fSU2_Tm_",
    "outputId": "263bc53c-7ca3-4783-fd77-8ab388c40b60",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "\n",
    "\n",
    "stopwordlist = [\n",
    "                'a', 'about', 'above', 'after', 'ain', 'all', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', \n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'how', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'just', 'll', 'm', 'ma',\n",
    "             'more', 'most', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'out','re',\n",
    "             's', 'same',  \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'then', 'there', 'these', 'they', 'this', 'those', \n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'was',\n",
    "             'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y'\n",
    "             ]\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Regex patterns\n",
    "    urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for d in textdata:\n",
    "        d = d.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        d = re.sub(urlPattern,' URL',d)\n",
    "        # Replace all emojis.\n",
    "        for emoji in emojis.keys():\n",
    "            d = d.replace(emoji, \" \" + emojis[emoji])        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        d = re.sub(userPattern,'', d)        \n",
    "        # Replace all non alphabets.\n",
    "        d = re.sub(alphaPattern, \" \", d)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        d = re.sub(sequencePattern, seqReplacePattern, d)\n",
    "        dwords = ''\n",
    "        for word in d.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            # If word not in stopwordlist\n",
    "            if len(word)>1:\n",
    "                \n",
    "                word = wordLemm.lemmatize(word)\n",
    "            \n",
    "                dwords += (word+' ')\n",
    "        processedText.append(dwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dividing Data into :- 1.training set \n",
    "                      2.Testing set \n",
    "        By 80:20"
   ],
   "metadata": {
    "id": "9zo-ZZi3Uuoa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cH_14H53Qt6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spliter=.8\n",
    "data=dataset.values.tolist()\n",
    "\n",
    "random.shuffle(data)\n",
    "Training = data[:int(len(data)*spliter)]\n",
    "Testing = data[int(len(data)*spliter):]\n",
    "training_posts = []\n",
    "training_labels = []\n",
    "testing_posts = []\n",
    "testing_labels = []\n",
    "for l,s in Training:\n",
    "  training_posts.append(s)\n",
    "  if l > 0:\n",
    "    training_labels.append(1)\n",
    "  else:\n",
    "    training_labels.append(0)\n",
    "for l,s in Testing:\n",
    "  testing_posts.append(s)\n",
    "  if l > 0:\n",
    "    testing_labels.append(1)\n",
    "  else:\n",
    "    testing_labels.append(0)\n",
    "training_posts=preprocess(training_posts)\n",
    "testing_posts=preprocess(testing_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word cloud of Dataset \n",
    "Depressed and non Depressed"
   ],
   "metadata": {
    "id": "jaW89lFtVO5u",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlwF73RX6f5s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#convert list to string and generate\n",
    "def cloud(posts):\n",
    "  unique_string=\" \".join(posts)\n",
    "  wordcloud = WordCloud(width = 1000, height = 500,stopwords=['URL','EMOJI','USER','quot','amp','http','tinyurl','http bit','lol','twitpic.com','bit.ly','bit','ly']+stopwordlist).generate(unique_string)\n",
    "  plt.figure(figsize=(20,12))\n",
    "  plt.imshow(wordcloud)\n",
    "  plt.axis(\"off\")\n",
    "  plt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\n",
    "  plt.show()\n",
    "  plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "depressed = []\n",
    "ndepressed = []\n",
    "for i in data:\n",
    "  if i[0]==0:\n",
    "    depressed.append(i[1])\n",
    "  else :\n",
    "    ndepressed.append(i[1])\n",
    "print(depressed[100])\n",
    "#cloud(depressed)\n",
    "#cloud(ndepressed)"
   ],
   "metadata": {
    "id": "ciC0j4u8cACx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "331cab98-8d30-42eb-8a95-178f8924476d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bar Graph of Distribution of Depressed and Non Depressed post \n"
   ],
   "metadata": {
    "id": "fjAidkeWb_b-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (4, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(['Depressed','Non-Depressed'], [len(depressed),len(ndepressed)], color =['blue','red'],\n",
    "        width = 0.2)\n",
    "ax=plt.gca()\n",
    "ax.set(ylim=[1000000,None])\n",
    "plt.xlabel(\"Post\")\n",
    "plt.ylabel(\"No. of Posts\")\n",
    "plt.title(\"Distribution of Depressed and Non Depressed\\n (million)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "DD-oIQfiUFj-",
    "outputId": "aa7c91ec-de88-4d08-928f-70b2049c8710",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# defining labels\n",
    "activities = ['Depressed', 'Non-Depressed']\n",
    " \n",
    "# portion covered by each label\n",
    "slices = [len(depressed),len(ndepressed)]\n",
    " \n",
    "# color for each label\n",
    "colors = ['r', 'y']\n",
    " \n",
    "# plotting the pie chart\n",
    "plt.pie(slices, labels = activities, colors=colors,\n",
    "        startangle=90, shadow = True, explode = (0, 0),\n",
    "        radius = 1.2, autopct = '%1.1f%%')\n",
    " \n",
    "# plotting legend\n",
    "plt.legend()\n",
    " \n",
    "# showing the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "DYPJwb-_yMJo",
    "outputId": "efc06518-847d-41c1-9962-38354111278c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9rgEPITejDK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cb2b7576-2c59-4995-b6b2-8669e7056bd8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "max_length = 32\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "padding_type='post'\n",
    "\n",
    "tokens = Tokenizer(num_words = 10000 , oov_token=oov_tok,lower=True)\n",
    "\n",
    "\n",
    "tokens.fit_on_texts(training_posts)\n",
    "word_index = tokens.word_index\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokens, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(tokens.get_config())\n",
    "\n",
    "vocab_size=len(word_index)\n",
    "training_sequences = tokens.texts_to_sequences(training_posts)\n",
    "training_padded = pad_sequences(training_sequences,maxlen=max_length, truncating=trunc_type, padding=padding_type)\n",
    "print(training_padded.shape)\n",
    "testing_sequences = tokens.texts_to_sequences(testing_posts)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length,truncating=trunc_type, padding=padding_type)\n",
    "\n",
    "training_padded = np.array(training_padded)\n",
    "testing_padded = np.array(testing_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcbIAu19US-D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1W5vZy2etitAblLdFn8_DxnsQKzfFJ98g\n",
    "# embeddings_index = {};\n",
    "# with open('/content/emb/glove.6B.100d.txt') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         coefs = np.asarray(values[1:], dtype='float32')\n",
    "#         embeddings_index[word] = coefs\n",
    "\n",
    "##########word2vc\n",
    "! kaggle datasets download -d danielwillgeorge/glove6b100dtxt -p /content/emb --unzip\n",
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load GloVe 100D embeddings\n",
    "with open('/content/emb/glove.6B.100d.txt') as fp:\n",
    "    for line in fp.readlines():\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlPuAQgQWcqP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlxEKMFJq26N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding,Conv1D,MaxPooling1D , Bidirectional\n",
    "\n",
    "model = Sequential([       \n",
    "              Embedding(input_dim=vocab_size+1,\n",
    "                        input_length = max_length,\n",
    "                        output_dim=embedding_dim,\n",
    "                        weights=[embeddings_matrix],\n",
    "                        trainable=False,\n",
    "                        ),\n",
    "              \n",
    "              Conv1D(64, 5, activation='relu'),\n",
    "              MaxPooling1D(pool_size=4),\n",
    "              Bidirectional(LSTM(64)),\n",
    "              Dropout(0.2),\n",
    "              #LSTM(32),\n",
    "              Dense(32, activation='relu'),\n",
    "              Dense(1, activation='sigmoid'),\n",
    "\n",
    "              ])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)\n"
   ],
   "metadata": {
    "id": "ZA5T0hlr5Wia",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCWldr4rSqdr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model Traning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0sv30Lr61X6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math \n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, mode = \"min\")\n",
    "# def lr_exp_decay(epoch, lr):\n",
    "#     k = 0.1\n",
    "#     return lr * math.exp(-k*epoch)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                 patience=1, \n",
    "                                 verbose=1, \n",
    "                                 factor=0.5, \n",
    "                                 min_lr=0.000001)\n",
    "\n",
    "\n",
    "history = model.fit(training_padded,\n",
    "                    training_labels,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=1000 ,\n",
    "                    #batch_size = 16,\n",
    "                    callbacks=[lr_reduction,callback],\n",
    "                    validation_data = (testing_padded,testing_labels), verbose = 1)\n",
    "\n",
    "model.save(\"Latest.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZLA2GaEKVRs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "model_saved = keras.models.load_model('/content/Latest.h5')\n",
    "tweet_negative = \"wants to be out in the sunshine but it's boring on my own.\" \n",
    "tweet_postive = \"Its a beautiful daaaaaaayyyyy!!!!!!!! This makes me happy\"\n",
    "#Changing words into Token and addeding Padding for tweet_negative\n",
    "negative_post = tokens.texts_to_sequences([tweet_negative])\n",
    "negative_post = pad_sequences(negative_post,maxlen=max_length, truncating=trunc_type, padding=padding_type)\n",
    "\n",
    "#Changing words into Token and addeding Padding for tweet_postive\n",
    "postive_post = tokens.texts_to_sequences([tweet_postive])\n",
    "postive_post = pad_sequences(postive_post,maxlen=max_length, truncating=trunc_type, padding=padding_type)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re6sU-JTupqE",
    "outputId": "17f02510-ef89-4764-b392-036b0a24816b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Giving input to the model to get result (tweet_negative)\n",
    "result  = model_saved.predict(negative_post)\n",
    "print(tweet_negative)\n",
    "if result >0.5 :\n",
    "  print(\"Non Depressed Person\")\n",
    "else:\n",
    "  print(\"Depressed Person\\n\")\n",
    "\n",
    "#Giving input to the model to get result (tweet_postive)\n",
    "print(tweet_postive)\n",
    "result = model_saved.predict(postive_post)\n",
    "if result >0.5 :\n",
    "  print(\"Non Depressed Person\")\n",
    "else:\n",
    "  print(\"Depressed Person\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wq_UIkfH1kSb",
    "outputId": "96921d05-151f-400e-a9ff-49a64ff80037",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbDBxbi5Bicz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "'''\n",
    "batch_size = 32\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    "))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}